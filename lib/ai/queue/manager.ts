// AI Queue System for Batch Processing and Load Balancing
import Bull from 'bull'
import Redis from 'ioredis'
import { aiOptimizer } from '../optimization/optimizer'
import { aiCache } from '../cache/manager'

// Queue configuration
const QUEUE_CONFIG = {
  REDIS: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT || '6379'),
    password: process.env.REDIS_PASSWORD
  },
  
  CONCURRENCY: {
    'skin-analysis': 5,
    'face-detection': 10,
    'batch-processing': 3,
    'model-training': 1
  },
  
  DELAYS: {
    'skin-analysis': 0,
    'face-detection': 0,
    'batch-processing': 1000,
    'model-training': 5000
  }
}

export class AIQueueManager {
  private static instance: AIQueueManager
  private queues: Map<string, Bull.Queue> = new Map()
  private redis: Redis | null = null
  private initialized = false
  private initializingPromise: Promise<void> | null = null

  constructor() {
    // Intentionally avoid connecting to Redis or initializing queues here.
    // Initialization will occur lazily when the manager is first used.
  }

  static getInstance(): AIQueueManager {
    if (!AIQueueManager.instance) {
      AIQueueManager.instance = new AIQueueManager()
    }
    return AIQueueManager.instance
  }

  // Initialize all queues
  private initializeQueues(): void {
    // If Redis isn't configured, skip initializing queues to avoid connection attempts
    if (!process.env.REDIS_HOST && !process.env.REDIS_URL) {
      return
    }
    const queueTypes = [
      'skin-analysis',
      'face-detection', 
      'batch-processing',
      'model-training'
    ]

    queueTypes.forEach(type => {
      const redisUrl = QUEUE_CONFIG.REDIS.password 
        ? `redis://:${QUEUE_CONFIG.REDIS.password}@${QUEUE_CONFIG.REDIS.host}:${QUEUE_CONFIG.REDIS.port}`
        : `redis://${QUEUE_CONFIG.REDIS.host}:${QUEUE_CONFIG.REDIS.port}`
      
      const queue = new Bull(`ai-${type}`, redisUrl, {
        defaultJobOptions: {
          removeOnComplete: 100,
          removeOnFail: 50,
          attempts: 3,
          backoff: 1000 // milliseconds
        }
      })

      // Set up processors
      this.setupQueueProcessor(queue, type)
      
      // Set up event listeners
      this.setupQueueListeners(queue, type)
      
      this.queues.set(type, queue)
    })

    console.log('‚úÖ AI queues initialized')
  }

  private async ensureInitialized(): Promise<void> {
    if (this.initialized) return
    if (!this.initializingPromise) {
      this.initializingPromise = (async () => {
        // Initialize Redis only when configured
        if (process.env.REDIS_HOST || process.env.REDIS_URL) {
          this.redis = new Redis(QUEUE_CONFIG.REDIS)
        }

        this.initializeQueues()
        this.initialized = true
      })()
    }
    await this.initializingPromise
  }

  // Setup queue processor
  private setupQueueProcessor(queue: Bull.Queue, type: string): void {
    const concurrency = QUEUE_CONFIG.CONCURRENCY[type as keyof typeof QUEUE_CONFIG.CONCURRENCY] || 5
    
    queue.process(concurrency, async (job) => {
      return this.processJob(job, type)
    })
  }

  // Setup queue event listeners
  private setupQueueListeners(queue: Bull.Queue, type: string): void {
    queue.on('completed', (job, result) => {
      console.log(`‚úÖ Job ${job.id} completed for ${type}`)
    })

    queue.on('failed', (job, err) => {
      console.error(`‚ùå Job ${job.id} failed for ${type}:`, err)
    })

    queue.on('stalled', (job) => {
      console.warn(`‚ö†Ô∏è Job ${job.id} stalled for ${type}`)
    })
  }

  // Process individual job
  private async processJob(job: Bull.Job, type: string): Promise<any> {
    const { data } = job
    
    try {
      switch (type) {
        case 'skin-analysis':
          return await this.processSkinAnalysis(data)
        case 'face-detection':
          return await this.processFaceDetection(data)
        case 'batch-processing':
          return await this.processBatch(data)
        case 'model-training':
          return await this.processModelTraining(data)
        default:
          throw new Error(`Unknown queue type: ${type}`)
      }
    } catch (error) {
      console.error(`Job processing error for ${type}:`, error)
      throw error
    }
  }

  // Add job to queue
  async addJob(
    type: string, 
    data: any, 
    options: Bull.JobOptions = {}
  ): Promise<Bull.Job> {
    await this.ensureInitialized()
    const queue = this.queues.get(type)
    if (!queue) {
      throw new Error(`Queue ${type} not found`)
    }

    const defaultOptions = {
      delay: QUEUE_CONFIG.DELAYS[type as keyof typeof QUEUE_CONFIG.DELAYS] || 0,
      ...options
    }

    return queue.add(data, defaultOptions)
  }

  // Add batch job
  async addBatchJob(
    type: string,
    items: any[],
    options: Bull.JobOptions = {}
  ): Promise<Bull.Job> {
    return this.addJob('batch-processing', {
      type,
      items,
      batchSize: items.length
    }, options)
  }

  // Process skin analysis job
  private async processSkinAnalysis(data: any): Promise<any> {
    const { image, userId, options } = data
    
    // Use optimized AI model
    const result = await aiOptimizer.optimizeInference(
      'skin-analysis',
      { image, userId },
      options
    )

    // Cache result
    await aiCache.set('AI_ANALYSIS', { userId, imageHash: this.hashImage(image) }, result.data)

    return result
  }

  // Process face detection job
  private async processFaceDetection(data: any): Promise<any> {
    const { image, userId, options } = data
    
    const result = await aiOptimizer.optimizeInference(
      'face-detection',
      { image, userId },
      options
    )

    return result
  }

  // Process batch job
  private async processBatch(data: any): Promise<any> {
    const { type, items, batchSize } = data
    const results = []

    // Process items in batches
    for (let i = 0; i < items.length; i += batchSize) {
      const batch = items.slice(i, i + batchSize)
      
      const batchResults = await Promise.all(
        batch.map(async (item: any) => {
          try {
            switch (type) {
              case 'skin-analysis':
                return await this.processSkinAnalysis(item)
              case 'face-detection':
                return await this.processFaceDetection(item)
              case 'batch-processing':
                return await this.processBatch(item)
              case 'model-training':
                return await this.processModelTraining(item)
              default:
                throw new Error(`Unknown queue type: ${type}`)
            }
          } catch (error) {
            console.error(`Batch item processing error for ${type}:`, error)
            return { error: error instanceof Error ? error.message : String(error), item }
          }
        })
      )
      
      results.push(...batchResults)
    }

    return {
      results,
      totalProcessed: items.length,
      successRate: results.filter(r => !r.error).length / items.length
    }
  }

  // Process model training job
  private async processModelTraining(data: any): Promise<any> {
    const { modelType, trainingData, options } = data
    
    // Implementation for model training
    console.log(`Training model ${modelType} with ${trainingData.length} samples`)
    
    return {
      modelType,
      status: 'completed',
      accuracy: 0.92,
      trainingTime: 15000 // ms
    }
  }

  // Get queue statistics
  async getQueueStats(type?: string): Promise<QueueStats[]> {
    await this.ensureInitialized()
    const stats: QueueStats[] = []
    
    const queuesToCheck = type ? [type] : Array.from(this.queues.keys())
    
    for (const queueType of queuesToCheck) {
      const queue = this.queues.get(queueType)
      if (!queue) continue
      
      const waiting = await queue.getWaiting()
      const active = await queue.getActive()
      const completed = await queue.getCompleted()
      const failed = await queue.getFailed()
      
      stats.push({
        type: queueType,
        waiting: waiting.length,
        active: active.length,
        completed: completed.length,
        failed: failed.length,
        total: waiting.length + active.length + completed.length + failed.length
      })
    }
    
    return stats
  }

  // Pause queue
  async pauseQueue(type: string): Promise<void> {
    await this.ensureInitialized()
    const queue = this.queues.get(type)
    if (queue) {
      await queue.pause()
    }
  }

  // Resume queue
  async resumeQueue(type: string): Promise<void> {
    await this.ensureInitialized()
    const queue = this.queues.get(type)
    if (queue) {
      await queue.resume()
    }
  }

  // Clear queue
  async clearQueue(type: string): Promise<void> {
    await this.ensureInitialized()
    const queue = this.queues.get(type)
    if (queue) {
      await queue.clean(0, 'completed')
      await queue.clean(0, 'failed')
    }
  }

  // Utility methods
  private hashImage(image: any): string {
    // Simple hash implementation
    return Buffer.from(JSON.stringify(image)).toString('base64').slice(0, 16)
  }

  // Graceful shutdown
  async shutdown(): Promise<void> {
    console.log('üîÑ Shutting down AI queues...')
    
    const closePromises = Array.from(this.queues.values()).map(queue => queue.close())
    await Promise.all(closePromises)
    
    if (this.redis) await this.redis.quit()
    console.log('‚úÖ AI queues shut down')
  }
}

// Type definitions
interface QueueStats {
  type: string
  waiting: number
  active: number
  completed: number
  failed: number
  total: number
}

// Export a lazy proxy so importing modules won't trigger Redis connections at build-time
const qHandler: ProxyHandler<any> = {
  get(_, prop) {
    const inst = AIQueueManager.getInstance()
    const val = (inst as any)[prop]
    if (typeof val === 'function') return val.bind(inst)
    return val
  }
}

export const aiQueue = new Proxy({}, qHandler) as AIQueueManager
